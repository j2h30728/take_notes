from langchain.document_loaders import SitemapLoader
from langchain.schema.runnable import RunnableLambda, RunnablePassthrough
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores.faiss import FAISS
from langchain.embeddings import OpenAIEmbeddings
from langchain.chat_models import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
import streamlit as st


llm = ChatOpenAI(
    temperature=0.1,
)

answers_prompt = ChatPromptTemplate.from_template(
    """
    ì£¼ì–´ì§„ contextë§Œì„ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”. ë‹µë³€í•  ìˆ˜ ì—†ëŠ” ê²½ìš°, 'ëª¨ë¥¸ë‹¤'ê³  ë§í•˜ê³  ì ˆëŒ€ ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”.
                                                  
    ê·¸ëŸ° ë‹¤ìŒ ë‹µë³€ì— 0ì ì—ì„œ 5ì  ì‚¬ì´ì˜ ì ìˆ˜ë¥¼ ë¶€ì—¬í•˜ì„¸ìš”. ë‹µë³€ì´ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ì •í™•íˆ ë‹µí•˜ë©´ ì ìˆ˜ê°€ ë†’ì•„ì•¼ í•˜ê³ , ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ ë‚®ì•„ì•¼ í•©ë‹ˆë‹¤.
    ì ìˆ˜ê°€ 0ì ì¼ì§€ë¼ë„ í•­ìƒ ì ìˆ˜ë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.
    Context: {context}
                                                  
    ì˜ˆì‹œ:
                                                  
    ì§ˆë¬¸: ë‹¬ê¹Œì§€ì˜ ê±°ë¦¬ëŠ” ì–¼ë§ˆë‚˜ ë˜ë‚˜ìš”?
    ë‹µë³€: ë‹¬ì€ 384,400km ë–¨ì–´ì ¸ ìˆìŠµë‹ˆë‹¤.
    ì ìˆ˜: 5
                                                  
    ì§ˆë¬¸: íƒœì–‘ê¹Œì§€ì˜ ê±°ë¦¬ëŠ” ì–¼ë§ˆë‚˜ ë˜ë‚˜ìš”?
    ë‹µë³€: ì˜ ëª¨ë¥´ê² ìŠµë‹ˆë‹¤.
    ì ìˆ˜: 0
                                                  
    ì´ì œ ë‹¹ì‹ ì˜ ì°¨ë¡€ì…ë‹ˆë‹¤!
    ì§ˆë¬¸: {question}
    """
)



def get_answers(inputs):
    docs = inputs["docs"]
    question = inputs["question"]
    answers_chain = answers_prompt | llm
    return {
        "question": question,
        "answers": [
            {
                "answer": answers_chain.invoke(
                    {"question": question, "context": doc.page_content}
                ).content,
                "source": doc.metadata["source"],
                "date": doc.metadata["lastmod"],
            }
            for doc in docs
        ],
    }

choose_prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            """
            ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€ë‹µí•˜ê¸° ìœ„í•´ ë°˜ë“œì‹œ ì•„ë˜ì˜ ë¯¸ë¦¬ ì œê³µëœ ë‹µë³€ë§Œì„ ì‚¬ìš©í•˜ì„¸ìš”.
            ê°€ì¥ ì ìˆ˜ê°€ ë†’ì€ (ë” ìœ ìš©í•œ) ë‹µë³€ì„ ì‚¬ìš©í•˜ê³ , ìµœì‹  ë‹µë³€ì„ ìš°ì„ ì ìœ¼ë¡œ ì„ íƒí•˜ì„¸ìš”.
            ì¶œì²˜ë¥¼ ë°˜ë“œì‹œ ì¸ìš©í•˜ê³ , ë‹µë³€ì— í¬í•¨ëœ ì¶œì²˜ëŠ” ë³€ê²½í•˜ì§€ ë§ê³  ê·¸ëŒ€ë¡œ ë°˜í™˜í•˜ì„¸ìš”.
            ë‹µë³€ë“¤: {answers}
            """,
        ),
        ("human", "{question}"),
    ]
)



def choose_answer(inputs):
    answers = inputs["answers"]
    question = inputs["question"]
    choose_chain = choose_prompt | llm
    condensed = "\n\n".join(
        f"{answer['answer']}\nSource:{answer['source']}\nDate:{answer['date']}\n"
        for answer in answers
    )
    return choose_chain.invoke(
        {
            "question": question,
            "answers": condensed,
        }
    )

def parse_page(soup):
    header = soup.find("header")
    footer = soup.find("footer")
    if header:
        header.decompose()
    if footer:
        footer.decompose()
    return (
        str(soup.get_text())
        .replace("\n", " ")
        .replace("\xa0", " ")
    )

@st.cache_data(show_spinner="Loading website...")
def load_website(url):
    splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(
        chunk_size=1000,
        chunk_overlap=200,
    )
    loader = SitemapLoader(
        url,
        filter_urls=[
            r"^(.*\/ai-gateway  \/).*",
            r"^(.*\/vectorize\/).*",
            r"^(.*\/workers-ai\/).*",
        ],
        parsing_function=parse_page,
    )
    loader.requests_per_second = 2
    docs = loader.load_and_split(text_splitter=splitter)
    vector_store = FAISS.from_documents(docs, OpenAIEmbeddings())
    return vector_store.as_retriever()

st.set_page_config(
    page_title="SiteGPT",
    page_icon="ğŸ–¥ï¸",
)


st.markdown(
    """
    # SiteGPT
            
    Ask questions about the content of a website.
            
    Start by writing the URL of the website on the sidebar.
"""
)


with st.sidebar:
    url = st.text_input(
        "Write down a URL",
        placeholder="https://example.com",
    )


if url:
    if ".xml" not in url:
        with st.sidebar:
            st.error("Sitemap URLì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        retriever = load_website(url)
        query = st.text_input("ì›¹ì‚¬ì´íŠ¸ì— ëŒ€í•´ ì§ˆë¬¸í•´ì£¼ì„¸ìš”.")
        if query:
            chain = (
                {
                    "docs": retriever,
                    "question": RunnablePassthrough(),
                }
                | RunnableLambda(get_answers)
                | RunnableLambda(choose_answer)
            )
            result = chain.invoke(query)
            st.markdown(result.content.replace("$", "\$"))